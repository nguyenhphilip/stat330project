{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from sklearn import datasets as sklearn_data\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import time\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hinton(matrix=None, max_weight=None, ax=None):\n",
    "    \"\"\"Draw Hinton diagram for visualizing a weight matrix.\"\"\"\n",
    "    ax = ax if ax is not None else plt.gca()\n",
    "\n",
    "    if not max_weight:\n",
    "        max_weight = 2 ** np.ceil(np.log(np.abs(matrix).max()) / np.log(2))\n",
    "\n",
    "    ax.patch.set_facecolor('gray')\n",
    "    ax.set_aspect('equal', 'box')\n",
    "    ax.xaxis.set_major_locator(plt.NullLocator())\n",
    "    ax.yaxis.set_major_locator(plt.NullLocator())\n",
    "\n",
    "    for (x, y), w in np.ndenumerate(matrix):\n",
    "        color = 'white' if w > 0 else 'black'\n",
    "        size = np.sqrt(np.abs(w) / max_weight)\n",
    "        rect = plt.Rectangle([x - size / 2, y - size / 2], size, size,\n",
    "                             facecolor=color, edgecolor=color)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    ax.autoscale_view()\n",
    "    ax.invert_yaxis()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "from scipy.stats import gamma\n",
    "import pandas as pd\n",
    "\n",
    "class BPCA(object):\n",
    "\n",
    "    def __init__(self, a_alpha=1e-3, b_alpha=1e-3, a_tau=1e-3, b_tau=1e-3, beta=1e-3):\n",
    "        # hyperparameters\n",
    "        self.a_alpha = a_alpha # parameter of alpha's prior (a Gamma distribution)\n",
    "        self.b_alpha = b_alpha # parameter of alpha's prior (a Gamma distribution)\n",
    "        self.a_tau = a_tau     # parameter of tau's prior (a Gamma distribution)\n",
    "        self.b_tau = b_tau     # parameter of tau's prior (a Gamma distribution)\n",
    "        self.beta = beta\n",
    "        # history of ELBOS\n",
    "        self.elbos = None\n",
    "        self.variations = None\n",
    "        # history of log likelihoods\n",
    "        self.loglikelihoods = None\n",
    "\n",
    "\n",
    "    def update(self):\n",
    "        \"\"\"fixed-point update of the Bayesian PCA\"\"\"\n",
    "        # inverse of the sigma^2\n",
    "        self.tau = self.a_tau_tilde / self.b_tau_tilde\n",
    "        # hyperparameters controlling the magnitudes of each column of the weight matrix\n",
    "        self.alpha = self.a_alpha_tilde / self.b_alpha_tilde\n",
    "        # covariance matrix of the latent variables\n",
    "        self.cov_z = np.linalg.inv(np.eye(self.q) + self.tau *\n",
    "                        (np.trace(self.cov_w) + np.dot(self.mean_w.T, self.mean_w)))\n",
    "        # mean of the latent variable\n",
    "        self.mean_z = self.tau * np.dot(np.dot(self.cov_z, self.mean_w.T), self.Xb - self.mean_mu)\n",
    "        # covariance matrix of the mean observation\n",
    "        self.cov_mu = np.eye(self.d) / (self.beta + self.b * self.tau)\n",
    "        # mean of the mean observation\n",
    "        self.mean_mu = self.tau * np.dot(self.cov_mu, np.sum(self.Xb-np.dot(self.mean_w,\n",
    "                        self.mean_z), axis=1)).reshape(self.d, 1)\n",
    "        # covariance matrix of each column of the weight matrix\n",
    "        self.cov_w = np.linalg.inv(np.diag(self.alpha) + self.tau *\n",
    "                        (self.b * self.cov_z + np.dot(self.mean_z, self.mean_z.T)))\n",
    "        # mean of each column of the weight matrix\n",
    "        self.mean_w = self.tau * np.dot(self.cov_w, np.dot(self.mean_z, (self.Xb-self.mean_mu).T)).T\n",
    "        # estimation of the b in alpha's Gamma distribution\n",
    "        self.b_alpha_tilde = self.b_alpha + 0.5 * (np.trace(self.cov_w) +\n",
    "                        np.diag(np.dot(self.mean_w.T, self.mean_w)))\n",
    "        # estimation of the b in tau's Gamma distribution\n",
    "        self.b_tau_tilde = self.b_tau + 0.5 * np.trace(np.dot(self.Xb.T, self.Xb)) + \\\n",
    "                        0.5 * self.b*(np.trace(self.cov_mu)+np.dot(self.mean_mu.flatten(), self.mean_mu.flatten())) + \\\n",
    "                        0.5 * np.trace(np.dot(np.trace(self.cov_w)+np.dot(self.mean_w.T, self.mean_w),\n",
    "                                        self.b*self.cov_z+np.dot(self.mean_z, self.mean_z.T))) + \\\n",
    "                        np.sum(np.dot(np.dot(self.mean_mu.flatten(), self.mean_w), self.mean_z)) + \\\n",
    "                        -np.trace(np.dot(self.Xb.T, np.dot(self.mean_w, self.mean_z))) + \\\n",
    "                        -np.sum(np.dot(self.Xb.T, self.mean_mu))\n",
    "        \n",
    "\n",
    "    def calculate_log_likelihood(self):\n",
    "        \"\"\"calculate the log likelihood of observing self.X\"\"\"\n",
    "        w = self.mean_w\n",
    "        c = np.eye(self.d)*self.tau + np.dot(w, w.T) \n",
    "        xc = self.X - self.X.mean(axis=1).reshape(-1,1)\n",
    "        s = np.dot(xc, xc.T) / self.N\n",
    "        self.s = s\n",
    "        c_inv_s = scipy.linalg.lstsq(c, s)[0]\n",
    "        loglikelihood = -0.5*self.N*(self.d*np.log(2*np.pi)+np.log(np.linalg.det(c))+np.trace(c_inv_s))\n",
    "        return loglikelihood\n",
    "\n",
    "\n",
    "    def calculate_ELBO(self):\n",
    "        '''ELBO = E_q[-log(q(theta))+log(p(theta)+log(p(Y|theta,X)))]\n",
    "                = -entropy + logprior + loglikelihood '''\n",
    "\n",
    "        # random sample\n",
    "        z = np.array([np.random.multivariate_normal(self.mean_z[:,i], self.cov_z) for i in range(self.b)]).T\n",
    "        mu = np.random.multivariate_normal(self.mean_mu.flatten(), self.cov_mu)\n",
    "        w = np.array([np.random.multivariate_normal(self.mean_w[i], self.cov_w) for i in range(self.d)])\n",
    "        alpha = np.random.gamma(self.a_alpha_tilde, 1/self.b_alpha_tilde)\n",
    "        tau = np.random.gamma(self.a_tau_tilde, 1/self.b_tau_tilde)\n",
    "\n",
    "        # entropy\n",
    "        # q(z)\n",
    "        entropy = np.sum(np.array([mvn.logpdf(z[:,i], self.mean_z[:,i], self.cov_z) for i in range(self.b)]))\n",
    "\n",
    "        # q(mu)\n",
    "        entropy += mvn.logpdf(mu, self.mean_mu.flatten(), self.cov_mu)\n",
    "\n",
    "        # q(W)\n",
    "        entropy += np.sum(np.array([mvn.logpdf(w[i], self.mean_w[i], self.cov_w) for i in range(self.d)]))\n",
    "\n",
    "        # q(alpha)\n",
    "        entropy += np.sum(gamma.logpdf(alpha, self.a_alpha_tilde, scale=1/self.b_alpha_tilde))\n",
    "\n",
    "        # q(tau)\n",
    "        entropy += gamma.logpdf(tau, self.a_tau_tilde, scale=1/self.b_tau_tilde)\n",
    "\n",
    "        # logprior\n",
    "        # p(z), z ~ N(0, I)\n",
    "        logprior = np.sum(np.array([mvn.logpdf(z[:,i], mean=np.zeros(self.q), cov=np.eye(self.q)) for i in range(self.b)]))\n",
    "\n",
    "        # p(w|alpha), conditional gaussian\n",
    "        logprior += np.sum(np.array([self.d/2*np.log(alpha[i]/(2*np.pi))-alpha[i]*np.sum(w[:,i]**2)/2 for i in range(self.q)]))\n",
    "\n",
    "        # p(alpha), alpha[i] ~ Gamma(a, b)\n",
    "        logprior += np.sum(gamma.logpdf(alpha, self.a_alpha, scale=1/self.b_alpha))\n",
    "\n",
    "        # p(mu), mu ~ N(0, I/beta)\n",
    "        logprior += mvn.logpdf(mu, mean=np.zeros(self.d), cov=np.eye(self.d)/self.beta)\n",
    "\n",
    "        # p(tau), tau ~ Gamma(c, d)\n",
    "        logprior += gamma.logpdf(tau, self.a_tau, scale=1/self.b_tau)\n",
    "\n",
    "        # loglikelihood\n",
    "        pred = np.dot(w, z) + mu.reshape(-1,1)\n",
    "        loglikelihood = np.sum(np.array([mvn.logpdf(self.Xb[:,i], pred[:,i], np.eye(self.d)/tau) for i in range(self.b)]))\n",
    "\n",
    "        return -entropy + logprior + loglikelihood\n",
    "\n",
    "\n",
    "    def batch_idx(self, i):\n",
    "        if self.b == self.N:\n",
    "            return np.arange(self.N)\n",
    "        idx1 = (i*self.b) % self.N\n",
    "        idx2 = ((i+1)*self.b) % self.N\n",
    "        if idx2 < idx1:\n",
    "            idx1 -= self.N\n",
    "        return np.arange(idx1, idx2)\n",
    "\n",
    "\n",
    "    def fit(self, X=None, batch_size=128, iters=500, print_every=100, verbose=False, trace_elbo=False, trace_loglikelihood=False):\n",
    "        \"\"\"fit the Bayesian PCA model using fixed-point update\"\"\"\n",
    "         # data, # of samples, dims\n",
    "        self.X = X.T # don't need to transpose X when passing it\n",
    "        self.d = self.X.shape[0]\n",
    "        self.N = self.X.shape[1]\n",
    "        self.q = self.d-1\n",
    "        self.ed = []\n",
    "        self.b = min(batch_size, self.N)\n",
    "\n",
    "        # variational parameters\n",
    "        self.mean_z = np.random.randn(self.q, self.b) # latent variable\n",
    "        self.cov_z = np.eye(self.q)\n",
    "        self.mean_mu = np.random.randn(self.d, 1)\n",
    "        self.cov_mu = np.eye(self.d)\n",
    "        self.mean_w = np.random.randn(self.d, self.q)\n",
    "        self.cov_w = np.eye(self.q)\n",
    "        self.a_alpha_tilde = self.a_alpha + self.d/2\n",
    "        self.b_alpha_tilde = np.abs(np.random.randn(self.q))\n",
    "        self.a_tau_tilde = self.a_tau + self.b * self.d / 2\n",
    "        self.b_tau_tilde = np.abs(np.random.randn(1))\n",
    "\n",
    "        # update\n",
    "        order = np.arange(self.N)\n",
    "        elbos = np.zeros(iters)\n",
    "        loglikelihoods = np.zeros(iters)\n",
    "        for i in range(iters):\n",
    "            idx = order[self.batch_idx(i)]\n",
    "            self.Xb = self.X[:,idx]\n",
    "            self.update()\n",
    "            if trace_elbo:\n",
    "                elbos[i] = self.calculate_ELBO()\n",
    "            if trace_loglikelihood:\n",
    "                loglikelihoods[i] = self.calculate_log_likelihood()\n",
    "            if verbose and i % print_every == 0:\n",
    "                print('Iter %d, LL: %f, alpha: %s' % (i, loglikelihoods[i], str(self.alpha)))\n",
    "        self.captured_dims()\n",
    "        self.elbos = elbos if trace_elbo else None\n",
    "        self.loglikelihoods = loglikelihoods if trace_loglikelihood else None\n",
    "\n",
    "\n",
    "    def captured_dims(self):\n",
    "        \"\"\"return the number of captured dimensions\"\"\"\n",
    "        sum_alpha = np.sum(1/self.alpha)\n",
    "        self.ed = np.array([i for i, inv_alpha in enumerate(1/self.alpha) if inv_alpha < sum_alpha/self.q])\n",
    "\n",
    "\n",
    "    def transform(self, X=None, full=True):\n",
    "        \"\"\"generate samples from the fitted model\"\"\"\n",
    "        X = self.X if X is None else X.T\n",
    "        if full:\n",
    "            w = self.mean_w\n",
    "            l = self.q\n",
    "        else:\n",
    "            w = self.mean_w[:, self.ed]\n",
    "            l = len(self.ed)\n",
    "        m = np.eye(l)*self.tau + np.dot(w.T, w)\n",
    "        inv_m = np.linalg.inv(m)\n",
    "        z = np.dot(np.dot(inv_m, w.T), X - self.mean_mu)\n",
    "        return z.T\n",
    "        # return np.array([np.random.multivariate_normal(z[:,i], inv_m*self.tau) for i in range(X.shape[1])])\n",
    "\n",
    "\n",
    "    def inverse_transform(self, z, full=True):\n",
    "        \"\"\"transform the latent variable into observations\"\"\"\n",
    "        z = z.T\n",
    "        if full:\n",
    "            w = self.mean_w\n",
    "        else:\n",
    "            w = self.mean_w[:, self.ed]\n",
    "        x = np.dot(w, z) + self.mean_mu\n",
    "        return x.T\n",
    "        # return np.array([np.random.multivariate_normal(x[:,i], np.eye(self.d)*self.tau) for i in range(z.shape[1])])\n",
    "\n",
    "        \n",
    "        # given a dataset, return the data in lower dimensional space\n",
    "    def fit_transform(self, X=None, batch_size=128, iters=500, print_every=100, verbose=False, trace_elbo=False, trace_loglikelihood=False):\n",
    "        self.fit(X, batch_size, iters, print_every, verbose, trace_elbo)\n",
    "        return self.transform()\n",
    "\n",
    "\n",
    "    def generate(self, size=1):\n",
    "        \"\"\"generate samples from the fitted model\"\"\"\n",
    "        # the principal axes\n",
    "        w = self.mean_w[:, self.ed]\n",
    "        # covariance matrix\n",
    "        c = np.eye(self.d)*self.tau + np.dot(w, w.T)\n",
    "        return np.array([np.random.multivariate_normal(self.mean_mu.flatten(), c) for i in range(size)])\n",
    "\n",
    "\n",
    "    def get_weight_matrix(self):\n",
    "        return self.mean_w\n",
    "\n",
    "\n",
    "    def get_inv_variance(self):\n",
    "        return self.alpha\n",
    "\n",
    "\n",
    "    def get_effective_dims(self):\n",
    "        return len(self.ed)\n",
    "\n",
    "\n",
    "    def get_cov_mat(self):\n",
    "        w = self.mean_w[:, self.ed]\n",
    "        c = np.eye(self.d)*self.tau + np.dot(w, w.T) \n",
    "        return c\n",
    "\n",
    "\n",
    "    def get_elbo(self):\n",
    "        return self.elbos\n",
    "\n",
    "\n",
    "    def get_loglikelihood(self):\n",
    "        return self.loglikelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>PCC</th>\n",
       "      <th>MacSlope</th>\n",
       "      <th>LitDep</th>\n",
       "      <th>DepO</th>\n",
       "      <th>DepA</th>\n",
       "      <th>pH</th>\n",
       "      <th>PctOM</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>...</th>\n",
       "      <th>Cu</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Al</th>\n",
       "      <th>Na</th>\n",
       "      <th>S</th>\n",
       "      <th>ECEC</th>\n",
       "      <th>Pb</th>\n",
       "      <th>Ni</th>\n",
       "      <th>Cd</th>\n",
       "      <th>Cr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.741597</td>\n",
       "      <td>0.620364</td>\n",
       "      <td>0.023652</td>\n",
       "      <td>0.347593</td>\n",
       "      <td>0.079306</td>\n",
       "      <td>-0.168619</td>\n",
       "      <td>-2.378835</td>\n",
       "      <td>-0.849057</td>\n",
       "      <td>0.589767</td>\n",
       "      <td>0.428009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086041</td>\n",
       "      <td>3.210545</td>\n",
       "      <td>2.818226</td>\n",
       "      <td>-0.729587</td>\n",
       "      <td>1.462195</td>\n",
       "      <td>-2.266726</td>\n",
       "      <td>0.537783</td>\n",
       "      <td>-0.893409</td>\n",
       "      <td>0.141998</td>\n",
       "      <td>0.072247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.778176</td>\n",
       "      <td>0.768939</td>\n",
       "      <td>0.091575</td>\n",
       "      <td>-0.201277</td>\n",
       "      <td>-0.395073</td>\n",
       "      <td>-0.279430</td>\n",
       "      <td>-2.467656</td>\n",
       "      <td>-0.920288</td>\n",
       "      <td>-0.174202</td>\n",
       "      <td>-0.136272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187631</td>\n",
       "      <td>3.697689</td>\n",
       "      <td>1.583526</td>\n",
       "      <td>-0.729587</td>\n",
       "      <td>0.275486</td>\n",
       "      <td>-2.363781</td>\n",
       "      <td>-0.227609</td>\n",
       "      <td>-0.860750</td>\n",
       "      <td>0.141998</td>\n",
       "      <td>-0.235589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.131512</td>\n",
       "      <td>0.768939</td>\n",
       "      <td>-0.638599</td>\n",
       "      <td>1.034873</td>\n",
       "      <td>0.587092</td>\n",
       "      <td>0.795635</td>\n",
       "      <td>-0.247128</td>\n",
       "      <td>-0.645541</td>\n",
       "      <td>-0.703103</td>\n",
       "      <td>-1.076740</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117140</td>\n",
       "      <td>-0.510413</td>\n",
       "      <td>-0.174986</td>\n",
       "      <td>-0.273207</td>\n",
       "      <td>-0.317868</td>\n",
       "      <td>-0.542934</td>\n",
       "      <td>-0.883659</td>\n",
       "      <td>-0.880345</td>\n",
       "      <td>0.141998</td>\n",
       "      <td>-0.851263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.102979</td>\n",
       "      <td>0.700366</td>\n",
       "      <td>-0.553695</td>\n",
       "      <td>-1.036514</td>\n",
       "      <td>0.025855</td>\n",
       "      <td>-0.097077</td>\n",
       "      <td>-0.306342</td>\n",
       "      <td>-1.052573</td>\n",
       "      <td>-0.732486</td>\n",
       "      <td>-1.076740</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015550</td>\n",
       "      <td>-0.230564</td>\n",
       "      <td>0.498487</td>\n",
       "      <td>-0.577460</td>\n",
       "      <td>-0.021191</td>\n",
       "      <td>-1.093619</td>\n",
       "      <td>0.100416</td>\n",
       "      <td>-0.873813</td>\n",
       "      <td>-0.785720</td>\n",
       "      <td>-0.543426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.176309</td>\n",
       "      <td>0.208923</td>\n",
       "      <td>-0.723503</td>\n",
       "      <td>0.466912</td>\n",
       "      <td>0.119394</td>\n",
       "      <td>1.149453</td>\n",
       "      <td>-1.268571</td>\n",
       "      <td>-0.940639</td>\n",
       "      <td>-0.820637</td>\n",
       "      <td>-1.076740</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117140</td>\n",
       "      <td>-0.209834</td>\n",
       "      <td>0.199166</td>\n",
       "      <td>-0.653524</td>\n",
       "      <td>-0.021191</td>\n",
       "      <td>-1.507160</td>\n",
       "      <td>-0.774318</td>\n",
       "      <td>-0.860750</td>\n",
       "      <td>0.141998</td>\n",
       "      <td>-0.851263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>-1.688892</td>\n",
       "      <td>0.814655</td>\n",
       "      <td>-0.485772</td>\n",
       "      <td>-2.205845</td>\n",
       "      <td>-1.158979</td>\n",
       "      <td>0.287587</td>\n",
       "      <td>0.419030</td>\n",
       "      <td>-0.472552</td>\n",
       "      <td>4.115777</td>\n",
       "      <td>1.970377</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.218730</td>\n",
       "      <td>-0.489683</td>\n",
       "      <td>-0.374533</td>\n",
       "      <td>-0.197144</td>\n",
       "      <td>-0.218976</td>\n",
       "      <td>0.847492</td>\n",
       "      <td>-0.883659</td>\n",
       "      <td>-0.906473</td>\n",
       "      <td>0.141998</td>\n",
       "      <td>-0.851263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.291296</td>\n",
       "      <td>-1.471126</td>\n",
       "      <td>-0.078233</td>\n",
       "      <td>1.914655</td>\n",
       "      <td>0.119394</td>\n",
       "      <td>-0.909953</td>\n",
       "      <td>-0.232325</td>\n",
       "      <td>-0.574310</td>\n",
       "      <td>-0.438652</td>\n",
       "      <td>-1.039122</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015550</td>\n",
       "      <td>0.961387</td>\n",
       "      <td>-0.212401</td>\n",
       "      <td>0.031046</td>\n",
       "      <td>-0.515653</td>\n",
       "      <td>0.024630</td>\n",
       "      <td>0.756466</td>\n",
       "      <td>0.151701</td>\n",
       "      <td>0.141998</td>\n",
       "      <td>1.919267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-0.130991</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.057613</td>\n",
       "      <td>1.302149</td>\n",
       "      <td>1.065183</td>\n",
       "      <td>-0.111593</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.148172</td>\n",
       "      <td>-0.468036</td>\n",
       "      <td>0.616103</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015550</td>\n",
       "      <td>0.878468</td>\n",
       "      <td>0.273996</td>\n",
       "      <td>0.031046</td>\n",
       "      <td>-0.021191</td>\n",
       "      <td>-0.047107</td>\n",
       "      <td>-0.446293</td>\n",
       "      <td>-0.024661</td>\n",
       "      <td>0.141998</td>\n",
       "      <td>5.305470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.188057</td>\n",
       "      <td>-0.431096</td>\n",
       "      <td>-0.214079</td>\n",
       "      <td>-0.101049</td>\n",
       "      <td>0.549676</td>\n",
       "      <td>-1.098656</td>\n",
       "      <td>-1.357392</td>\n",
       "      <td>-0.482728</td>\n",
       "      <td>0.384083</td>\n",
       "      <td>-0.625316</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117140</td>\n",
       "      <td>0.951022</td>\n",
       "      <td>-0.249816</td>\n",
       "      <td>-0.425334</td>\n",
       "      <td>-0.416761</td>\n",
       "      <td>-0.656869</td>\n",
       "      <td>0.756466</td>\n",
       "      <td>-0.063853</td>\n",
       "      <td>-0.785720</td>\n",
       "      <td>2.842777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.096752</td>\n",
       "      <td>-0.191089</td>\n",
       "      <td>-0.723503</td>\n",
       "      <td>-1.036514</td>\n",
       "      <td>1.771926</td>\n",
       "      <td>-0.274894</td>\n",
       "      <td>0.241388</td>\n",
       "      <td>0.819776</td>\n",
       "      <td>-0.497419</td>\n",
       "      <td>0.164678</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117140</td>\n",
       "      <td>-0.365306</td>\n",
       "      <td>-0.324646</td>\n",
       "      <td>-0.045017</td>\n",
       "      <td>-0.218976</td>\n",
       "      <td>1.497343</td>\n",
       "      <td>-0.446293</td>\n",
       "      <td>0.112509</td>\n",
       "      <td>0.141998</td>\n",
       "      <td>1.303594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Elevation       PCC  MacSlope    LitDep      DepO      DepA        pH  \\\n",
       "0   -0.741597  0.620364  0.023652  0.347593  0.079306 -0.168619 -2.378835   \n",
       "1   -0.778176  0.768939  0.091575 -0.201277 -0.395073 -0.279430 -2.467656   \n",
       "2    0.131512  0.768939 -0.638599  1.034873  0.587092  0.795635 -0.247128   \n",
       "3    0.102979  0.700366 -0.553695 -1.036514  0.025855 -0.097077 -0.306342   \n",
       "4    0.176309  0.208923 -0.723503  0.466912  0.119394  1.149453 -1.268571   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "93  -1.688892  0.814655 -0.485772 -2.205845 -1.158979  0.287587  0.419030   \n",
       "94   0.291296 -1.471126 -0.078233  1.914655  0.119394 -0.909953 -0.232325   \n",
       "95  -0.130991  0.574648  0.057613  1.302149  1.065183 -0.111593 -0.780055   \n",
       "96  -0.188057 -0.431096 -0.214079 -0.101049  0.549676 -1.098656 -1.357392   \n",
       "97  -0.096752 -0.191089 -0.723503 -1.036514  1.771926 -0.274894  0.241388   \n",
       "\n",
       "       PctOM         P         K  ...        Cu        Fe        Al        Na  \\\n",
       "0  -0.849057  0.589767  0.428009  ...  0.086041  3.210545  2.818226 -0.729587   \n",
       "1  -0.920288 -0.174202 -0.136272  ...  0.187631  3.697689  1.583526 -0.729587   \n",
       "2  -0.645541 -0.703103 -1.076740  ... -0.117140 -0.510413 -0.174986 -0.273207   \n",
       "3  -1.052573 -0.732486 -1.076740  ... -0.015550 -0.230564  0.498487 -0.577460   \n",
       "4  -0.940639 -0.820637 -1.076740  ... -0.117140 -0.209834  0.199166 -0.653524   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "93 -0.472552  4.115777  1.970377  ... -0.218730 -0.489683 -0.374533 -0.197144   \n",
       "94 -0.574310 -0.438652 -1.039122  ... -0.015550  0.961387 -0.212401  0.031046   \n",
       "95  0.148172 -0.468036  0.616103  ... -0.015550  0.878468  0.273996  0.031046   \n",
       "96 -0.482728  0.384083 -0.625316  ... -0.117140  0.951022 -0.249816 -0.425334   \n",
       "97  0.819776 -0.497419  0.164678  ... -0.117140 -0.365306 -0.324646 -0.045017   \n",
       "\n",
       "           S      ECEC        Pb        Ni        Cd        Cr  \n",
       "0   1.462195 -2.266726  0.537783 -0.893409  0.141998  0.072247  \n",
       "1   0.275486 -2.363781 -0.227609 -0.860750  0.141998 -0.235589  \n",
       "2  -0.317868 -0.542934 -0.883659 -0.880345  0.141998 -0.851263  \n",
       "3  -0.021191 -1.093619  0.100416 -0.873813 -0.785720 -0.543426  \n",
       "4  -0.021191 -1.507160 -0.774318 -0.860750  0.141998 -0.851263  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "93 -0.218976  0.847492 -0.883659 -0.906473  0.141998 -0.851263  \n",
       "94 -0.515653  0.024630  0.756466  0.151701  0.141998  1.919267  \n",
       "95 -0.021191 -0.047107 -0.446293 -0.024661  0.141998  5.305470  \n",
       "96 -0.416761 -0.656869  0.756466 -0.063853 -0.785720  2.842777  \n",
       "97 -0.218976  1.497343 -0.446293  0.112509  0.141998  1.303594  \n",
       "\n",
       "[98 rows x 24 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"centered_scaled_adiantum.csv\").drop(columns = \"Unnamed: 0\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpca = BPCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, LL: 0.000000, alpha: [  9.76802988  15.80390304  15.43448442  61.98978251  18.66355549\n",
      "  22.86663974 132.60808276  16.14426793  12.16308623   7.10089321\n",
      "   8.96685457  26.11223667  11.63868126  78.55875318  39.59525825\n",
      "  22.42909622  33.50310392   5.1796093  202.30260304  15.23313485\n",
      "  12.47960021  50.32882773  97.21370338]\n",
      "Iter 1000, LL: 0.000000, alpha: [ 16.5335219    8.17926531  39.83024533 445.47628935  52.94296606\n",
      " 445.47628935   8.16677778 445.47628935 445.47628935 445.47628935\n",
      " 445.47628935 445.47628935 445.47628935 445.47628935 445.47628935\n",
      "  41.68059773 445.47628935 445.47628935 445.47628935  74.68544224\n",
      " 445.47628935 445.47628935 445.47628935]\n",
      "Iter 2000, LL: 0.000000, alpha: [ 16.539978     8.1956945   36.61713129 445.4693397   54.11894857\n",
      " 445.4693397    8.15348774 445.4693397  445.4693397  445.4693397\n",
      " 445.4693397  445.4693397  445.4693397  445.4693397  445.4693397\n",
      "  45.38570599 445.4693397  445.4693397  445.4693397   74.88119829\n",
      " 445.4693397  445.4693397  445.4693397 ]\n",
      "Iter 3000, LL: 0.000000, alpha: [ 16.54132481   8.24669007  36.60882006 445.46836386  54.1886869\n",
      " 445.46836386   8.10385572 445.46836386 445.46836386 445.46836386\n",
      " 445.46836386 445.46836386 445.46836386 445.46836386 445.46836386\n",
      "  45.41345619 445.46836386 445.46836386 445.46836386  74.92534804\n",
      " 445.46836386 445.46836386 445.46836386]\n",
      "Iter 4000, LL: 0.000000, alpha: [ 16.54124934   8.41898341  36.64778467 445.47102963  54.19527555\n",
      " 445.47102963   7.94208602 445.47102963 445.47102963 445.47102963\n",
      " 445.47102963 445.47102963 445.47102963 445.47102963 445.47102963\n",
      "  45.35266057 445.47102963 445.47102963 445.47102963  74.92970696\n",
      " 445.47102963 445.47102963 445.47102963]\n",
      "Iter 5000, LL: 0.000000, alpha: [ 16.5400616    8.9236977   36.65479166 445.49387028  54.20357064\n",
      " 445.49387028   7.5244488  445.49387028 445.49387028 445.49387028\n",
      " 445.49387028 445.49387028 445.49387028 445.49387028 445.49387028\n",
      "  45.34661072 445.49387028 445.49387028 445.49387028  74.94837098\n",
      " 445.49387028 445.49387028 445.49387028]\n",
      "Iter 6000, LL: 0.000000, alpha: [ 16.53526392   9.52652338  36.65865069 445.54530409  54.2172637\n",
      " 445.54530409   7.10979629 445.54530409 445.54530409 445.54530409\n",
      " 445.54530409 445.54530409 445.54530409 445.54530409 445.54530409\n",
      "  45.35228073 445.54530409 445.54530409 445.54530409  74.98993638\n",
      " 445.54530409 445.54530409 445.54530409]\n",
      "Iter 7000, LL: 0.000000, alpha: [ 16.53162871   9.68980061  36.65932614 445.5650509   54.22160475\n",
      " 445.5650509    7.00701842 445.5650509  445.5650509  445.5650509\n",
      " 445.5650509  445.5650509  445.5650509  445.5650509  445.5650509\n",
      "  45.3540201  445.5650509  445.5650509  445.5650509   75.00435437\n",
      " 445.5650509  445.5650509  445.5650509 ]\n",
      "Iter 8000, LL: 0.000000, alpha: [ 16.53063652   9.71567793  36.65931001 445.56901088  54.22228742\n",
      " 445.56901088   6.99025612 445.56901088 445.56901088 445.56901088\n",
      " 445.56901088 445.56901088 445.56901088 445.56901088 445.56901088\n",
      "  45.35418774 445.56901088 445.56901088 445.56901088  75.00676166\n",
      " 445.56901088 445.56901088 445.56901088]\n",
      "Iter 9000, LL: 0.000000, alpha: [ 16.53040921   9.7206575   36.65929212 445.56985776  54.22241962\n",
      " 445.56985776   6.98694046 445.56985776 445.56985776 445.56985776\n",
      " 445.56985776 445.56985776 445.56985776 445.56985776 445.56985776\n",
      "  45.35420565 445.56985776 445.56985776 445.56985776  75.00722864\n",
      " 445.56985776 445.56985776 445.56985776]\n"
     ]
    }
   ],
   "source": [
    "bpca.fit(data.values, iters = 10000, verbose = True, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpca.get_effective_dims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit, transform, inverse transform the images\n",
    "pca = PCA(n_components=bpca.get_effective_dims())\n",
    "new_X_pca = pca.inverse_transform(pca.fit_transform(data.values))\n",
    "new_X_bpca = bpca.inverse_transform(bpca.transform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98, 24)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X_bpca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 23)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpca.get_weight_matrix().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98, 24)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpca.inverse_transform(bpca.transform(full=False), full=False).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98, 24)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpca.inverse_transform(bpca.transform()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98, 17)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 98 data points, each 23 dimensional, Z\n",
    "bpca.transform(full=False).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 24)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate values from fitted model\n",
    "bpca.generate(size = 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 98)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpca.transform().T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98, 23)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpca.transform().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98, 24)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpca.inverse_transform(bpca.transform()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpca.captured_dims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
